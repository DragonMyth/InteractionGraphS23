run: DDPPO
name: exp14
local_dir: /checkpoint/jungdam/Research/ScaDive/data/learning/multiagent/fencing/task/
checkpoint_freq: 100
checkpoint_at_end: true
stop: 
    time_total_s: 720000
config:
    env: HumanoidFencing
    log_level: WARN
    gamma: 0.99
    lambda: 0.95
    clip_param: 0.2
    kl_coeff: 0.0
    vf_clip_param: 1000
    num_sgd_iter: 20
    lr: 0.00001
    sgd_minibatch_size: 500
    horizon: 900
    train_batch_size: 100000
    rollout_fragment_length: 250
    num_envs_per_worker: 10
    num_cpus_per_worker: 10
    num_gpus_per_worker: 0
    remote_worker_envs: true
    shuffle_sequences: true
    framework: torch
    model:
        custom_model: moe_additive
        custom_model_config:
            log_std_type: constant
            sample_std: 0.1
            expert_size_in: 281
            expert_hiddens:
                - [128, 128]
                - [128, 128]
            expert_activations:
                - [relu, relu, linear]
                - [relu, relu, linear]
            expert_init_weights:
                - [1.0, 1.0, 0.01]
                - [1.0, 1.0, 0.01]
            expert_log_std_types:
                - constant
                - constant
            expert_sample_stds:
                - 0.1
                - 0.1
            expert_checkpoints:
                - data/temp/fc_policy_phase_trigon.pt
                - data/temp/fc_policy_phase_trigon.pt
            expert_learnable:
                - True
                - True
    num_workers: 8
    num_gpus: 0
    batch_mode: truncate_episodes
    observation_filter: NoFilter
    multiagent: None
    env_config:
        lazy_creation: false
        project_dir: /private/home/jungdam/Research/ScaDive/
        fps_sim: 480
        fps_con: 30
        self_collision: true
        add_noise: false
        verbose: false
        state:
            # 'body', 'imitation', 'interaction', 'task'
            choices: ['body', 'game']
        action:
            # 'absolute', 'relative'
            type: "absolute"
            range_min: -3.0
            range_max: 3.0
            range_min_pol: -3.0
            range_max_pol: 3.0
        reward: 
            fn_def:
                default:
                    name: total
                    op: mul
                    child_nodes:
                      - name: fencing
                        op: mul
                        child_nodes:
                          - name: out_of_arena
                            op: leaf
                            weight: 1.0
                            kernel: 
                                type: none
                          - name: falldown
                            op: leaf
                            weight: 1.0
                            kernel: 
                                type: none
                          - name: win
                            op: leaf
                            weight: 1.0
                            kernel: 
                                type: none
                      - name: imitation
                        op: mul
                        child_nodes:
                          - name: pose_pos
                            op: leaf
                            weight: 1.0
                            kernel: 
                                type: gaussian
                                scale: 40.0
                          - name: pose_vel
                            op: leaf
                            kernel: 
                                type: gaussian
                                scale: 2.0
                          - name: ee
                            op: leaf
                            weight: 1.0
                            kernel: 
                                type: gaussian
                                scale: 5.0
                          - name: root
                            op: leaf
                            weight: 1.0
                            kernel: 
                                type: gaussian
                                scale: 2.5
                          - name: com
                            op: leaf
                            weight: 1.0
                            kernel: 
                                type: gaussian
                                scale: 2.5
            fn_map:
                - default
                - default
        early_term:
            # 'sim_div', 'sim_window', task_end', 'falldown', 'low_reward'
            choices:
                - ref_motion_end
                - low_reward
            low_reward_thres: 0.1
            eoe_margin: 0.5
        character:
            name:
                - player1
                - player2
            char_info_module:
                - humanoid_fencing_char_info.py
                - humanoid_fencing_char_info.py
            sim_char_file:
                - data/character/humanoid_fencing.urdf
                - data/character/humanoid_fencing.urdf
            ref_motion_scale:
                - 1.0
                - 1.0
            base_motion_file:
                - data/motion/multiagent/fencing/player1.bvh
                - data/motion/multiagent/fencing/player2.bvh
            ref_motion_db:
                -
                    data:
                        file:
                            - data/motion/multiagent/fencing/edited/Capture1_subject1_stageII_edited.bvh
                -
                    data:
                        file:
                            - data/motion/multiagent/fencing/edited/Capture1_subject2_stageII_edited.bvh
            actuation: 
                - spd
                - spd
            self_collision: 
                - true
                - true
            environment_file: []