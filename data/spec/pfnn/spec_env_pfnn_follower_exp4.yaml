run: DDPPO
name: exp4
local_dir: /checkpoint/jungdam/Research/ScaDive/data/learning/pfnn/follower/
checkpoint_freq: 100
checkpoint_at_end: true
stop: 
    time_total_s: 720000
config:
    env: HumanoidFollower
    log_level: WARN
    gamma: 0.99
    lambda: 0.95
    clip_param: 0.2
    kl_coeff: 0.0
    vf_clip_param: 1000
    num_sgd_iter: 20
    lr: 0.00002
    sgd_minibatch_size: 500
    horizon: 1800
    train_batch_size: 100000
    rollout_fragment_length: 100
    normalize_actions: False
    clip_actions: True
    num_envs_per_worker: 10
    num_cpus_per_worker: 10
    num_gpus_per_worker: 0
    remote_worker_envs: true
    framework: torch
    model:
        custom_model: task_agnostic_policy_type1
        custom_model_config:
            log_std_type: constant
            sample_std: 0.1
            task_encoder_type: "mlp"
            task_encoder_inputs:
                - body
                - task
            task_encoder_output_dim: 32
            task_encoder_layers:
                - type: fc
                  hidden_size: 128
                  activation: "relu"
                  init_weight: 
                      name: normc
                      std: 1.0
                - type: fc
                  hidden_size: 128
                  activation: "relu"
                  init_weight: 
                      name: normc
                      std: 1.0
                - type: fc
                  hidden_size: output
                  activation: "linear"
                  init_weight: 
                      name: normc
                      std: 0.01
            
            body_encoder_enable: false

            motor_decoder_type: "mlp"
            motor_decoder_inputs:
                - body
                - task
            motor_decoder_layers:
                - type: fc
                  hidden_size: 512
                  activation: "relu"
                  init_weight: 
                      name: normc
                      std: 1.0
                - type: fc
                  hidden_size: 512
                  activation: "relu"
                  init_weight: 
                      name: normc
                      std: 1.0
                - type: fc
                  hidden_size: 512
                  activation: "relu"
                  init_weight: 
                      name: normc
                      std: 1.0
                - type: fc
                  hidden_size: output
                  activation: "linear"
                  init_weight: 
                      name: normc
                      std: 0.01
            motor_decoder_load_weights: data/etc/pretrained_model/pfnn/TrainModel_2021-10-15_01-43-01/9/task_agnostic_policy_motor_decoder.pt
            motor_decoder_learnable: false
            
            value_fn_layers:
                - type: fc
                  hidden_size: 128
                  activation: "relu"
                  init_weight: 
                      name: normc
                      std: 1.0
                - type: fc
                  hidden_size: 128
                  activation: "relu"
                  init_weight: 
                      name: normc
                      std: 1.0
                - type: fc
                  hidden_size: output
                  activation: "linear"
                  init_weight: 
                      name: normc
                      std: 0.01
    num_workers: 8
    num_gpus: 0
    batch_mode: truncate_episodes
    observation_filter: NoFilter
    env_config:
        lazy_creation: true
        project_dir: /private/home/jungdam/Research/ScaDive/
        fps_sim: 480
        fps_con: 30
        add_noise: false
        verbose: false
        ground_contact_stiffness: 50000
        ground_contact_damping: 0.2
        state:
            choices: ['body', 'goal']
            body_type: facing_R6_h
        action:
            # 'absolute', 'relative'
            type: "absolute"
            range_min: -3.0
            range_max: 3.0
            range_min_pol: -3.0
            range_max_pol: 3.0
        reward: 
            fn_def:
                default:
                    name: total
                    op: mul
                    child_nodes:
                      - name: pos
                        op: leaf
                        weight: 1.0
                        kernel: 
                            type: gaussian
                            scale: 2.0
                      - name: dir
                        op: leaf
                        weight: 1.0
                        kernel: 
                            type: gaussian
                            scale: 5.0
            fn_map:
                - default
        early_term:
            choices:
                - low_reward
            low_reward_thres: 0.1
            low_reward_duration: 2.0
            eoe_margin: 0.5
        character:
            name:
                - agent1
            char_info_module:
                - pfnn_char_info.py
            sim_char_file:
                - data/character/pfnn.urdf
            ref_motion_scale:
                - 1.0
            base_motion_file:
                - data/motion/pfnn/pfnn_hierarchy.bvh
            ref_motion_db:
                -
                    data:
                        file:
                            - data/motion/pfnn/pfnn_follower_init_states_path.bvh
            actuation: 
                - spd
            self_collision: 
                - true
            environment_file: []
        goal:
            type: path
            radius: 10
            speed: 1
            future_input_stride: 2