# PPO -> SAC
run: SAC
name: exp26
local_dir: "/checkpoint/jungdam/Research/ScaDive/data/learning/multiagent/fight/"
checkpoint_freq: 100
checkpoint_at_end: true
stop: 
    time_total_s: 240000
config:
    env: HumanoidFight
    gamma: 0.995
    no_done_at_end: true
    normalize_actions: false
    Q_model:
      hidden_activation: relu
      hidden_layer_sizes: [256, 256]
    policy_model:
      hidden_activation: relu
      hidden_layer_sizes: [256, 256]
    tau: 0.005
    target_entropy: auto
    no_done_at_end: True
    n_step: 1
    prioritized_replay: False
    target_network_update_freq: 1
    train_batch_size: 4096
    timesteps_per_iteration: 32768
    learning_starts: 131072
    optimization:
      actor_learning_rate: 0.00002
      critic_learning_rate: 0.0001
      entropy_learning_rate: 0.0001
    horizon: 3000
    num_workers: 8
    num_gpus: 0
    batch_mode: truncate_episodes
    observation_filter: MeanStdFilter
    multiagent: None
    env_config:
        project_dir: /private/home/jungdam/Research/ScaDive/
        # Simulation
        fps_sim: 480
        fps_con: 30
        self_collision: true
        add_noise: true
        verbose: false
        sim_window: 120
        eoe_margin: 2.0
        # 'none', 'spd', 'pd', 'cpd', 'cp', 'v
        actuation: spd
        # 'imitation', 'emerge_coop', 'emerge_comp'
        mode: emerge_comp
        # 'heading', 'carry', 'dribble', 'fight'
        task: fight
        state:
            # 'body', 'imitation', 'interaction', 'task'
            choices: ['body', 'task']
        action:
            # 'absolute', 'relative'
            type: "absolute"
            range_min: -3.0
            range_max: 3.0
            range_min_pol: -6.0
            range_max_pol: 6.0
        reward: 
            # 'sum', 'mul'
            type: sum
            # 'pose', 'vel', 'ee', 'root', 'com', 'interaction'
            choices: []
            fn_def:
                default:
                    name: total
                    op: add
                    child_nodes:
                      - name: high_root
                        op: leaf
                        weight: 0.0
                        kernel: 
                            type: gaussian
                            scale: 3.0
                      - name: vel_to_center
                        op: leaf
                        weight: 0.25
                        kernel: 
                            type: gaussian
                            scale: 3.0
                      - name: stay_at_center
                        op: leaf
                        weight: 0.25
                        kernel: 
                            type: gaussian
                            scale: 1.5
                      - name: push_opponent
                        op: leaf
                        weight: 0.5
                        kernel: 
                            type: gaussian
                            scale: 1.5
                      - name: win
                        op: leaf
                        weight: 1.0
                        kernel: 
                            type: none
            fn_map:
                - default
                - default
        early_term:
            # 'task_complete', 'falldown', 'root_fail', 'low_reward'
            choices:
                - task_complete
            low_reward_thres: 0.1
            falldown_contactable_body:
                - lankle
                - lknee
                - rankle
                - rknee
        character:
            char_info_module:
                - amass_char_info.py
                - amass_char_info.py
            sim_char_file:
                - data/character/amass.urdf
                - data/character/amass.urdf
            ref_motion_scale:
                - 1.0
                - 1.0
            base_motion_file:
                - data/motion/multiagent/fight/actor1.bvh
                - data/motion/multiagent/fight/actor2.bvh
            ref_motion_files: []
            environment_file:
                - data/character/ring_circle.urdf