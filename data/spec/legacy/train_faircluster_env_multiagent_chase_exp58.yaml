run: PPO
name: exp58
local_dir: "/checkpoint/jungdam/Research/ScaDive/data/learning/multiagent/chase/"
checkpoint_freq: 100
checkpoint_at_end: true
stop: 
    time_total_s: 720000
config:
    log_level: WARN
    env: HumanoidChase
    gamma: 0.99
    lambda: 0.95
    clip_param: 0.2
    kl_coeff: 0.0
    vf_clip_param: 1000
    num_sgd_iter: 20
    lr: 0.00001
    sgd_minibatch_size: 1000
    horizon: 900
    train_batch_size: 100000
    rollout_fragment_length: 256
    # grad_clip: 10
    use_pytorch: true
    num_envs_per_worker: 4
    num_cpus_per_worker: 4
    num_gpus_per_worker: 0
    remote_worker_envs: true
    shuffle_sequences: false
    model:
        custom_model: task_agnostic_policy_type1
        custom_options:
            log_std_type: state_independent
            sample_std: 0.2
            lstm_enable: true
            task_encoder_enable: true
            task_encoder_output_dim: 32
            body_encoder_enable: true
            body_encoder_output_dim: 32
            body_encoder_learnable: true
            body_encoder_weights: data/etc/pretrained_model/walk_run/body_encoder.pt
            motor_decoder_learnable: true
            motor_decoder_weights: data/etc/pretrained_model/walk_run/motor_decoder.pt
    num_workers: 8
    num_gpus: 0
    batch_mode: truncate_episodes
    observation_filter: NoFilter
    multiagent: None
    env_config:
        project_dir: /private/home/jungdam/Research/ScaDive/
        # Simulation
        fps_sim: 600
        fps_con: 30
        self_collision: true
        add_noise: false
        verbose: false
        sim_window: 120
        eoe_margin: 0.5
        # 'none', 'spd', 'pd', 'cpd', 'cp', 'v
        actuation: spd
        # 'heading', 'carry', 'dribble', 'fight', 'chase'
        task: chase
        state:
            # 'body', 'task'
            choices: ['body', 'task']
        action:
            # 'absolute', 'relative'
            type: "absolute"
            range_min: -3.0
            range_max: 3.0
            range_min_pol: -3.0
            range_max_pol: 3.0
        reward: 
            # 'sum', 'mul'
            type: sum
            # 'pose', 'vel', 'ee', 'root', 'com', 'interaction'
            choices: []
            fn_def:
                hunter:
                    name: total
                    op: add
                    child_nodes:
                      - name: vel_to_prey_rel
                        op: leaf
                        weight: 1.0
                        kernel: 
                            type: gaussian
                            scale: 3.0
                      - name: out_of_ring
                        op: leaf
                        weight: 10.0
                        kernel: 
                            type: none
                      - name: falldown
                        op: leaf
                        weight: 10.0
                        kernel: 
                            type: none
                      - name: win
                        op: leaf
                        weight: 10.0
                        kernel: 
                            type: none
                prey:
                    name: total
                    op: add
                    child_nodes:
                      - name: vel_from_hunter_rel
                        op: leaf
                        weight: 1.0
                        kernel: 
                            type: gaussian
                            scale: 3.0
                      - name: out_of_ring
                        op: leaf
                        weight: 10.0
                        kernel: 
                            type: none
                      - name: falldown
                        op: leaf
                        weight: 10.0
                        kernel: 
                            type: none
                      - name: win
                        op: leaf
                        weight: 10.0
                        kernel: 
                            type: none
            fn_map:
                - hunter
                - prey
        early_term:
            # 'task_complete', 'falldown', 'root_fail', 'low_reward'
            choices:
                - task_complete
            falldown_contactable_body:
                - lankle
                - lknee
                - rankle
                - rknee
        character:
            char_info_module:
                - amass_char_info.py
                - amass_char_info.py
            sim_char_file:
                - data/character/amass.urdf
                - data/character/amass.urdf
            ref_motion_scale:
                - 1.0
                - 1.0
            base_motion_file:
                - data/motion/multiagent/fight/actor1.bvh
                - data/motion/multiagent/fight/actor2.bvh
            ref_motion_files: []
            environment_file:
                - data/character/ring_square.urdf